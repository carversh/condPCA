{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scanpy\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import partial\n",
    "# from scipy.spatial.distance import cosine\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTS:\n",
    "# tested identical normalization\n",
    "# tested identical standardization\n",
    "# tested identical regression of (residual) AGE, SEX, and BATCH\n",
    "# tested identiacal regression (residual) of AGE, SEX, BATCH, and CELL TYPE\n",
    "\n",
    "# TO DO:\n",
    "# check iterative PCA\n",
    "# only add cell type to regress out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD GENE NAMES AND CELL NAMES TO THE OUTPUTTED EMBEDDINGS\n",
    "# ADD VARIABLE GENES TO CONDITIONAL AND STANDARD PCA\n",
    "# OUTPUT ITERATIVE PCA AS SETS OF DICTIONARIES\n",
    "# make these functions not callable: (because they only pertain to conditional and standard)\n",
    "  # test.Normalize()\n",
    "  # test.Standardize()\n",
    "# CHECK ITER\n",
    "# check arguments\n",
    "# check that no columns or rows with all zeros\n",
    "# ensure that factor variables are NOT integers or real\n",
    "# what if no covariates\n",
    "# subsetting to most variable genes, iterPCA and stand/cond PCA will be different\n",
    "# output mean variance relationship\n",
    "# ensure no rows or columns with 0 entries\n",
    "#  MUST ADD VARGENES SUBSET HERE !\n",
    "# might want to modify iterative PCs outputted vs condPCA, but can always make new model\n",
    "\n",
    "class condPCA(object):\n",
    "    def __init__(self, count_matrix_path, metadata_path, object_columns, vars_to_regress=True, n_PCs=20, random_seed=9989999, vargenes_IterPCA=500, vargenes_Stand_Cond=300):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        count_matrix:\n",
    "            Count matrix that must be QC'd\n",
    "\n",
    "        metadata:\n",
    "            metadata containing cell type labels named \"celltype\"\n",
    "\n",
    "        object_columns:\n",
    "            columns that will be one hot encoded/columns that are factors \n",
    "\n",
    "        vars_to_regress:\n",
    "            list of variables to regress out\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.count_matrix = scanpy.read(count_matrix_path) # cells x genes, pd.read_csv(count_matrix_path, sep='\\t', header=0, index_col=0)\n",
    "       \n",
    "        self.metadata = pd.read_csv(metadata_path, sep='\\t', header=0, index_col=0)\n",
    "        \n",
    "        if vars_to_regress:\n",
    "            \n",
    "            self.vars_to_regress = self.metadata.columns\n",
    "        \n",
    "        else: # if vars_to_regress is a list, convert to pandas core Index object\n",
    "            \n",
    "            self.vars_to_regress = pd.Index(vars_to_regress)\n",
    "\n",
    "        # one hot encode necessary metadata variables\n",
    "        self.object_columns = object_columns # obtain columns that must be one hot encoded\n",
    "        \n",
    "        self.metadata[self.object_columns] = self.metadata[self.object_columns].astype(object) # convert these columns to objects\n",
    "\n",
    "        self.random_seed = random_seed # set random seed\n",
    "        \n",
    "        self.n_PCs = n_PCs # number of PCs to extract\n",
    "\n",
    "        self.vargenes_IterPCA = vargenes_IterPCA # number of variable genes for iterative pca\n",
    "\n",
    "        self.vargenes_Stand_Cond = vargenes_Stand_Cond # number of variable genes for standard and conditional pca\n",
    "\n",
    "    def Normalize(self):\n",
    "        \"\"\" \n",
    "        Normalize and take log1p of count data (for conditional and standard, not iterative)\n",
    "        \"\"\"\n",
    "        \n",
    "        # update scanpy object to normalize all rows, so every cell sums to 10k\n",
    "        scanpy.pp.normalize_total(self.count_matrix, target_sum = 10000) \n",
    "       \n",
    "        # log transform\n",
    "        scanpy.pp.log1p(self.count_matrix) \n",
    "\n",
    "        # subset to variable genes of interest\n",
    "        scanpy.pp.highly_variable_genes(self.count_matrix, n_top_genes=self.vargenes_Stand_Cond)\n",
    "\n",
    "    def Standardize(self):\n",
    "        \"\"\" \n",
    "        Standardize count data AND metadata (for conditional and standard, not iterative)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Standardize count data\n",
    "\n",
    "        # if matrix is sparse, make dense\n",
    "        if scipy.sparse.issparse(self.count_matrix.X):\n",
    "            \n",
    "            self.count_matrix.X = self.count_matrix.X.todense()\n",
    "        \n",
    "        # only subset the matrix to the most variable genes\n",
    "        self.standardized_count_data = self._standardize(self.count_matrix.X[:, self.count_matrix.var['highly_variable']])\n",
    "\n",
    "        # Process metadata/covariates for standardization:\n",
    "\n",
    "        # subset to only variables that you want to regress out\n",
    "        self.metadata = self.metadata[self.vars_to_regress] \n",
    "       \n",
    "        # WARNING IN FOLLOWING LINE BECAUSE CONVERTING OBJECT THAT LOOKS NUMERIC TO BE ONE HOT ENCODED, this is batch\n",
    "        self.IterPCA_metadata = pd.get_dummies(self.metadata, drop_first=False)\n",
    "        \n",
    "        # Convert factor covariates to dummy variables dropping one column \n",
    "        self.metadata = pd.get_dummies(self.metadata, drop_first=True) \n",
    "        \n",
    "        self.standardized_metadata = self._standardize(self.metadata)\n",
    "    \n",
    "    def _standardize(self, mat): # simple function performing standardization\n",
    "        \n",
    "        # compute means of genes or covariates\n",
    "        mean_vector = np.mean(mat, axis=0)\n",
    "       \n",
    "       # compute standard deviation of genes or covariates\n",
    "        std_vector = np.std(mat, axis=0)\n",
    "        \n",
    "        # standardize by gene or covariates\n",
    "        stand_mat = (mat - mean_vector) / std_vector \n",
    "        return stand_mat\n",
    "    \n",
    "    def _regress_covariates(self, standardized_metadata, standardized_count_data): # function regressing set of covariates\n",
    "        \n",
    "        # append ones to standardized meta for intercept\n",
    "        standardized_metadata = np.c_[np.ones((standardized_metadata.shape[0], 1)), standardized_metadata] \n",
    "        \n",
    "        # compute inverse of np.matmul(A^T, A) where A is the standardized metadata or covariates\n",
    "        inv_cov = np.linalg.pinv(np.matmul(standardized_metadata.T, standardized_metadata) ) \n",
    "        \n",
    "        # compute betas per gene\n",
    "        betas = np.apply_along_axis(self._column_wise_regression, axis=0, arr=standardized_count_data, inv_cov_mat=inv_cov, standardized_metadata_mat=standardized_metadata) \n",
    "        \n",
    "        # compute prediction\n",
    "        prediction = np.matmul(standardized_metadata, betas) # compute prediction\n",
    "        \n",
    "        # compute residual\n",
    "        residual = standardized_count_data - prediction \n",
    "        \n",
    "        standardized_residual = self._standardize(residual)\n",
    "        \n",
    "        return standardized_residual\n",
    "\n",
    "    def _column_wise_regression(self, column, inv_cov_mat, standardized_metadata_mat): # perform regression of metadata/covariates across all genes\n",
    "        \n",
    "        # ensure that every column is a numpy array --> was running into issues in iterative PCA\n",
    "        column = np.array(column)\n",
    "       \n",
    "        # compute betas for a given gene (dimension of covariates plus 1 for intercept)\n",
    "        betas = inv_cov_mat @ standardized_metadata_mat.T @ column \n",
    "        \n",
    "        return betas\n",
    "    \n",
    "    def _fit_pca(self, mat, iterPCA, iterPCA_genenames, iterPCA_cellnames): # fitting PCA\n",
    "        \n",
    "        # instantiate PCA with hyperparameters\n",
    "        pca = PCA(n_components=self.n_PCs, random_state=self.random_seed) \n",
    "        \n",
    "        # projections (of input data onto eigenvectors)\n",
    "        pca.fit(mat) \n",
    "       \n",
    "        # retrieve eigenvectors/gene loadings\n",
    "        gene_loadings = pca.components_ \n",
    "\n",
    "        # retrive cell embeddings\n",
    "        cell_embeddings = pca.transform(mat)\n",
    "\n",
    "        # retrieve eigenvalues\n",
    "        eigenvalues = pca.explained_variance_ \n",
    "        \n",
    "        # if iterative PCA \n",
    "        if iterPCA: \n",
    "            \n",
    "            # convert gene loadings to dataframe\n",
    "            gene_loadings = pd.DataFrame(gene_loadings.T, index = list(iterPCA_genenames ), columns = [f'PC_{i}' for i in range(1, (gene_loadings.T.shape[1]+1))])\n",
    "                \n",
    "            # convert cell embeddings to dataframe\n",
    "            cell_embeddings = pd.DataFrame(cell_embeddings, index = list(iterPCA_cellnames), columns = [f'PC_{i}' for i in range(1, (cell_embeddings.shape[1]+1))])\n",
    "\n",
    "        # convert eigenvalues to dataframe\n",
    "        eigenvalues = pd.DataFrame(eigenvalues, index = [f'PC_{i}' for i in range(1, (eigenvalues.shape[0]+1))], columns=[\"Eigenvalues\"])\n",
    "\n",
    "        # if Standard or Conditional PCA, construct dataframes based on gene and cell list from original count matrix\n",
    "        if not iterPCA: \n",
    "\n",
    "            # convert gene loadings to dataframe\n",
    "            gene_loadings = pd.DataFrame(gene_loadings.T, index = list(self.count_matrix.var_names[self.count_matrix.var['highly_variable']] ), columns = [f'PC_{i}' for i in range(1, (gene_loadings.T.shape[1]+1))])\n",
    "                \n",
    "            # convert cell embeddings to dataframe\n",
    "            cell_embeddings = pd.DataFrame(cell_embeddings, index = list(self.count_matrix.obs_names), columns = [f'PC_{i}' for i in range(1, (cell_embeddings.shape[1]+1))])\n",
    "      \n",
    "        return cell_embeddings, gene_loadings, eigenvalues\n",
    "    \n",
    "    def _compute_BIC(self, mat): # compute BIC significant PCs\n",
    "        return 0\n",
    "    \n",
    "    def _fit_model(self, standardized_metadata, standardized_count_data, iterPCA=False, iterPCA_genenames=False, iterPCA_cellnames=False): # regress out covariates and then input into PCA\n",
    "\n",
    "        # regress out covariates (including celltype) and retrieve standardized residual\n",
    "        standardized_residual = self._regress_covariates(standardized_metadata = standardized_metadata, standardized_count_data= standardized_count_data)\n",
    "        \n",
    "        # np.save('/Users/shayecarver/condPCA/final_method/standardized_residual.npy', standardized_residual) # THIS CAN BE DELETED, IT WAS FOR DEBUGGING\n",
    "        \n",
    "        # if not iterative PCA, able to add gene names and cell names here, but must subset if IterPCA\n",
    "        if not iterPCA: \n",
    "            # return standardized residual as a dataframe with gene and cell names:\n",
    "            standardized_residual = pd.DataFrame(standardized_residual, index = list(self.count_matrix.obs_names), columns = list(self.count_matrix.var_names[self.count_matrix.var['highly_variable']]))\n",
    "\n",
    "        if iterPCA:\n",
    "            # return standardized residual as a dataframe with gene and cell names of the given subset:\n",
    "            standardized_residual = pd.DataFrame(standardized_residual, index = list(iterPCA_cellnames), columns = list(iterPCA_genenames))\n",
    "        \n",
    "        # perform PCA on residualized matrix\n",
    "        return( self._fit_pca(standardized_residual, iterPCA=iterPCA, iterPCA_genenames=iterPCA_genenames, iterPCA_cellnames=iterPCA_cellnames) )\n",
    "\n",
    "    def _mapping_IterPCA_subset_dataframes_to_PCA(self, metadata, CT_exp_column): \n",
    "        \n",
    "        # extract indices of the cells that belong to the particular cell type of interest (indicated by CT_column, which is a column name)\n",
    "        indices_given_ct = self.dataframe_CT_indices[CT_exp_column]\n",
    "    \n",
    "        # subset the count data to the cells belonging to the cell type\n",
    "        metadata_subset_to_CT = metadata[indices_given_ct]\n",
    "\n",
    "        # Re-process from log-normalized data to standadization of the matrix (find new set of variable genes for the subset)\n",
    "        \n",
    "        # make a tmp copy and subset the matrix to cells in the particular cell type identify highly variable genes from log normalized count matrix\n",
    "        # Subset the Scanpy object to the specified row/cell indices\n",
    "        tmp_copy_counts = self.count_matrix[indices_given_ct].copy() \n",
    "        \n",
    "        # find highly variable genes after subsetting count matrix to the cells in a particular cell type\n",
    "        scanpy.pp.highly_variable_genes(tmp_copy_counts, n_top_genes=self.vargenes_IterPCA) \n",
    "\n",
    "        # subset the scanpy object to the most variable genes\n",
    "        tmp_copy_counts_subset = tmp_copy_counts[:, tmp_copy_counts.var['highly_variable']]\n",
    "        \n",
    "        # Re-standardize count databecause it has just been subset\n",
    "        count_data_subset_to_CT = self._standardize(tmp_copy_counts_subset.X) \n",
    "        \n",
    "        # Re-standardize metadata because it has just been subset\n",
    "        metadata_subset_to_CT = self._standardize(metadata_subset_to_CT)\n",
    "\n",
    "        # extract the cell names or barcodes of the cells belonging to the cell type of interest\n",
    "        cellnames = tmp_copy_counts_subset.obs_names \n",
    "\n",
    "        # extract the gene names of the genes belonging to the most variable genes within that subset\n",
    "        genenames = tmp_copy_counts_subset.var_names \n",
    "\n",
    "        # fit the given model by regressing out covariates and performing PCA\n",
    "        return [self._fit_model(standardized_metadata=metadata_subset_to_CT,standardized_count_data = count_data_subset_to_CT, iterPCA=True, iterPCA_genenames=genenames, iterPCA_cellnames = cellnames)] \n",
    "\n",
    "    def CondPCA_fit(self):\n",
    "       \n",
    "        # fit linear model (regress out covariates) and fit PCA -- covariates contain cell type\n",
    "        self.COND_cell_embeddings, self.COND_gene_loadings, self.COND_eigenvalues = self._fit_model(standardized_metadata=self.standardized_metadata,standardized_count_data= self.standardized_count_data)\n",
    "\n",
    "        # compute BIC\n",
    "\n",
    "    def StandardPCA_fit(self):\n",
    "        \n",
    "        # remove celltype from covariate space\n",
    "        standardized_metadata_minus_celltype = self.standardized_metadata.drop(columns = self.standardized_metadata.filter(like=\"celltype\", axis=1).columns )\n",
    "        \n",
    "        # fit linear model (regress out covariates) and fit PCA -- covariates do not contain cell type\n",
    "        self.STANDARD_cell_embeddings, self.STANDARD_gene_loadings, self.STANDARD_eigenvalues = self._fit_model(standardized_metadata=standardized_metadata_minus_celltype,standardized_count_data= self.standardized_count_data)\n",
    "    \n",
    "    def Iter_PCA_fit(self):\n",
    "\n",
    "        # remove celltype from standardized covariate space\n",
    "        metadata_minus_celltype = self.standardized_metadata.drop(columns = self.standardized_metadata.filter(like=\"celltype\", axis=1).columns )  \n",
    "        \n",
    "        # get dataframe with boolean indices for each cell type\n",
    "        self.dataframe_CT_indices = self.IterPCA_metadata.filter(like=\"celltype\", axis=1).astype(bool)   \n",
    "        \n",
    "        # get the name of the columns that indicate a cell type\n",
    "        celltype_colnames = self.dataframe_CT_indices.columns  \n",
    "\n",
    "        # Create a partially applied function to subset the counts matrix by each cell type (one matrix per celltype)\n",
    "        subset_counts_matrix_fcn = partial(self._mapping_IterPCA_subset_dataframes_to_PCA, metadata_minus_celltype) \n",
    "\n",
    "        # output a list of PCA outputs\n",
    "        results_list = list(map(subset_counts_matrix_fcn, celltype_colnames))  \n",
    "        ITER_cell_embeddings, ITER_gene_loadings, ITER_eigenvalues = zip(*[result[0] for result in results_list])\n",
    "\n",
    "        # create list of cell types in the order by which iterative PCA has computed the outputs\n",
    "        celltypes = [s.replace('celltype_', '') for s in list(test.dataframe_CT_indices.columns )]\n",
    "\n",
    "        self.ITER_cell_embeddings = dict(zip(celltypes, ITER_cell_embeddings))\n",
    "        \n",
    "        self.ITER_gene_loadings = dict(zip(celltypes, ITER_gene_loadings))\n",
    "        \n",
    "        self.ITER_eigenvalues = dict(zip(celltypes, ITER_eigenvalues))\n",
    "\n",
    "        # returns a dictionary of PCA fittings on each cell type\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate class\n",
    "test = condPCA(count_matrix_path=\"/Users/shayecarver/condPCA/final_method/test_matrix.txt\", metadata_path=\"/Users/shayecarver/condPCA/final_method/test_metadata.txt\", object_columns=['Batch', 'Sex','celltype']) # object_columns are columns that must be factors\n",
    "test.Normalize()\n",
    "test.Standardize()\n",
    "test.CondPCA_fit()\n",
    "test.StandardPCA_fit()\n",
    "test.Iter_PCA_fit()\n",
    "\n",
    "# ensure that the outputted dataframes are dataframes and have the right gene names\n",
    "# output iterative as a dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum should be ~2000: 2000.0000395791126\n",
      "sum should be ~2000: 2000.0001817499913\n",
      "sum should be ~2000: 2000.0\n",
      "sum should be ~2000: 1999.9999999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading in from my method\n",
    "norm_a = test.count_matrix.X\n",
    "scale_a = test.standardized_count_data\n",
    "standardized_residual_batch_age_sex_A = np.load('/Users/shayecarver/condPCA/final_method/my_method_standardized_residual_test_matrix.npy')\n",
    "standardized_residual_batch_age_sex_celltype_A = np.load('/Users/shayecarver/condPCA/final_method/standardized_residual.npy')\n",
    "\n",
    "# reading in from seurat or base R\n",
    "norm_b = np.array(pd.read_csv(\"/Users/shayecarver/condPCA/final_method/norm_test_matrix.txt\", sep='\\t', header=0, index_col=0))\n",
    "scale_b = np.array(pd.read_csv(\"/Users/shayecarver/condPCA/final_method/scale_test_matrix.txt\", sep='\\t', header=0, index_col=0))\n",
    "standardized_residual_batch_age_sex_B = np.array(pd.read_csv(\"/Users/shayecarver/condPCA/final_method/SEURAT_scale_counts_regress_batch_age_sex.txt\", sep='\\t', header=0, index_col=0)) # residual computed in seurat\n",
    "standardized_residual_batch_age_sex_B = np.array(pd.read_csv(\"/Users/shayecarver/condPCA/final_method/base_R_standardized_residual_test_matrix.txt\", sep='\\t', header=0, index_col=0)) #residual computed in base R\n",
    "standardized_residual_batch_age_sex_celltype_B = np.array(pd.read_csv(\"/Users/shayecarver/condPCA/final_method/base_R_standardized_residual_test_matrix_w_CELLTYPE.txt\", sep='\\t', header=0, index_col=0)) #residual computed in base R\n",
    "\n",
    "# function checking consistency between two matrices (taking inner product of matched index column of two matrices)\n",
    "def inner_prod_similarity(MatrixA, MatrixB): # compute inner product similarity between two matrices\n",
    "    similarity = np.sum(MatrixA * MatrixB, axis=0) / (np.linalg.norm(MatrixA, axis=0) * np.linalg.norm(MatrixB, axis=0))\n",
    "    print(f'sum should be ~2000: {sum(similarity)}')\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# printing the sum of the normalized innter product between two matrices (which should equal 2000 because there are 2000 genes, 2000 columns)\n",
    "inner_prod_similarity(norm_a,norm_b) \n",
    "inner_prod_similarity(scale_a,scale_b)\n",
    "inner_prod_similarity(standardized_residual_batch_age_sex_A,standardized_residual_batch_age_sex_B)\n",
    "inner_prod_similarity(standardized_residual_batch_age_sex_celltype_A,standardized_residual_batch_age_sex_celltype_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AM231_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
